{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-3-0b78b3ee756e>, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-0b78b3ee756e>\"\u001b[1;36m, line \u001b[1;32m19\u001b[0m\n\u001b[1;33m    url = input(‘https://www.nobroker.in/‘)\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "import urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "import json\n",
    "import ast\n",
    "import os\n",
    "from urllib.request import Request, urlopen\n",
    "\n",
    "# For ignoring SSL certificate errors\n",
    "\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "# Input from user\n",
    "\n",
    "url = input(‘https://www.nobroker.in/‘)\n",
    "\n",
    "# Making the website believe that you are accessing it using a mozilla browser\n",
    "\n",
    "req = Request(url, headers={‘User-Agent’: ‘Mozilla/5.0’})\n",
    "webpage = urlopen(req).read()\n",
    "\n",
    "# Creating a BeautifulSoup object of the html page for easy extraction of data.\n",
    "\n",
    "soup = BeautifulSoup(webpage, ‘html.parser’)\n",
    "html = soup.prettify(‘utf-8’)\n",
    "property_json = {}\n",
    "property_json[‘Details_Broad’] = {}\n",
    "property_json[‘Address’] = {}\n",
    "\n",
    "# Extract Title of the property listing\n",
    "\n",
    "for title in soup.findAll(‘title’):\n",
    "property_json[‘Title’] = title.text.strip()\n",
    "break\n",
    "\n",
    "for meta in soup.findAll(‘meta’, attrs={‘name’: ‘description’}):\n",
    "property_json[‘Detail_Short’] = meta[‘content’].strip()\n",
    "\n",
    "for div in soup.findAll(‘div’, attrs={‘class’: ‘character-count-truncated’}):\n",
    "property_json[‘Details_Broad’][‘Description’] = div.text.strip()\n",
    "\n",
    "for (i, script) in enumerate(soup.findAll(‘script’,\n",
    "attrs={‘type’: ‘application/ld+json’})):\n",
    "if i == 0:\n",
    "json_data = json.loads(script.text)\n",
    "property_json[‘Details_Broad’][‘Number of Rooms’] = json_data[‘numberOfRooms’] property_json[‘Details_Broad’][‘Floor Size (in sqft)’] = json_data[‘floorSize’][‘value’] property_json[‘Address’][‘Street’] = json_data[‘address’][‘streetAddress’] property_json[‘Address’][‘Locality’] = json_data[‘address’][‘addressLocality’] property_json[‘Address’][‘Region’] = json_data[‘address’][‘addressRegion’] property_json[‘Address’][‘Postal Code’] = json_data[‘address’][‘postalCode’] if i == 1:\n",
    "json_data = json.loads(script.text)\n",
    "property_json[‘Price in $’] = json_data[‘offers’][‘price’] property_json[‘Image’] = json_data[‘image’] break\n",
    "\n",
    "with open(‘data.json’, ‘w’) as outfile:\n",
    "json.dump(property_json, outfile, indent=4)\n",
    "\n",
    "with open(‘output_file.html’, ‘wb’) as file:\n",
    "file.write(html)\n",
    "print (‘———-Extraction of data is complete. Check json file.———-‘)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
